{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import listdir, path\n",
    "import numpy as np\n",
    "import pickle, argparse\n",
    "from glob import glob\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_root': 'LipGAN_dataset_local', 'batch_size': 200, 'lr': 0.001, 'img_size': 96, 'logdir': 'logs_ipynb', 'all_images': 'filenames.pkl'}\n"
     ]
    }
   ],
   "source": [
    "from easydict import EasyDict\n",
    "\n",
    "args = EasyDict(data_root='LipGAN_dataset_local',\n",
    "               batch_size=200,\n",
    "               lr=1e-3,\n",
    "               img_size=96,\n",
    "               logdir='logs_ipynb',\n",
    "               all_images='filenames.pkl')\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will be training on 1678240 images\n"
     ]
    }
   ],
   "source": [
    "import itertools \n",
    "\n",
    "half_window_size = 4\n",
    "mel_step_size = 27\n",
    "    \n",
    "def frame_id(fname):\n",
    "    return int(os.path.basename(fname).split('.')[0])\n",
    "\n",
    "def choose_ip_frame(frames, gt_frame):\n",
    "    selected_frames = [f for f in frames if np.abs(frame_id(gt_frame) - frame_id(f)) >= 6]\n",
    "    if len(selected_frames) == 0:\n",
    "        selected_frames = frames\n",
    "        \n",
    "    return np.random.choice(selected_frames)\n",
    "\n",
    "def get_audio_segment(center_frame, spec):\n",
    "    center_frame_id = frame_id(center_frame)\n",
    "    start_frame_id = center_frame_id - half_window_size\n",
    "\n",
    "    start_idx = int((81./25.) * start_frame_id) # 25 is fps of LRS2\n",
    "    end_idx = start_idx + mel_step_size\n",
    "\n",
    "    return spec[:, start_idx : end_idx] if end_idx <= spec.shape[1] else None\n",
    "\n",
    "def bgr2rgb(x):\n",
    "    temp = x[:, :, 0].copy()\n",
    "    x[:, :, 0] = x[:, :, 2]\n",
    "    x[:, :, 2] = temp\n",
    "    \n",
    "    return x\n",
    "\n",
    "if not path.exists(args.logdir):\n",
    "    os.mkdir(args.logdir)\n",
    "\n",
    "if path.exists(path.join(args.logdir, args.all_images)):\n",
    "    all_images = pickle.load(open(path.join(args.logdir, args.all_images), 'rb'))\n",
    "else:\n",
    "    all_images = glob(path.join(\"{}/train/*/*/*.jpg\".format(args.data_root)))\n",
    "    pickle.dump(all_images, open(path.join(args.logdir, args.all_images), 'wb'), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print (\"Will be training on {} images\".format(len(all_images)))\n",
    "\n",
    "np.random.shuffle(all_images)\n",
    "batches = all_images\n",
    "\n",
    "def fetch_data():\n",
    "    while(True):\n",
    "        index = np.random.randint(0, len(batches))\n",
    "\n",
    "        '''Get a frame'''\n",
    "        img_name = batches[index]\n",
    "        gt_fname = os.path.basename(img_name)\n",
    "        dir_name = img_name.replace(gt_fname, '')\n",
    "        frames = glob(dir_name + '/*.jpg')\n",
    "\n",
    "        if len(frames) < 12:\n",
    "            continue\n",
    "\n",
    "        '''Get a melspectrogram'''\n",
    "        mel_fname = dir_name + \"./mels.npz\"\n",
    "        mel = np.load(mel_fname)['spec']\n",
    "        mel = get_audio_segment(gt_fname, mel)\n",
    "\n",
    "        if mel is None or mel.shape[1] != mel_step_size:\n",
    "            continue\n",
    "\n",
    "        if sum(np.isnan(mel.flatten())) > 0:\n",
    "            continue    \n",
    "\n",
    "        '''Ground Truth & IP '''\n",
    "        img_gt = cv2.imread(img_name)        \n",
    "        img_gt = bgr2rgb(img_gt)\n",
    "        img_gt = img_gt / 255.0\n",
    "        img_gt = cv2.resize(img_gt, (args.img_size, args.img_size))\n",
    "\n",
    "        img_gt_masked = img_gt.copy()\n",
    "        img_gt_masked[args.img_size//2:] = 0 \n",
    "\n",
    "        ip_fname = choose_ip_frame(frames, gt_fname)\n",
    "        img_ip = cv2.imread(ip_fname)\n",
    "        img_ip = bgr2rgb(img_ip)\n",
    "        img_ip = img_ip / 255.0\n",
    "        img_ip = cv2.resize(img_ip, (args.img_size, args.img_size))\n",
    "\n",
    "        break\n",
    "\n",
    "    return (img_gt, img_gt_masked, img_ip, mel)\n",
    " \n",
    "def gen(): \n",
    "    for i in itertools.count(1):\n",
    "        img_gt_list = []\n",
    "        img_gt_masked_list = []\n",
    "        img_ip_list = []\n",
    "        mel_list = []\n",
    "        for _ in range(args.batch_size):\n",
    "            img_gt, img_gt_masked, img_ip, mel = fetch_data()\n",
    "            img_gt_list.append(img_gt)\n",
    "            img_gt_masked_list.append(img_gt_masked)\n",
    "            img_ip_list.append(img_ip)\n",
    "            mel_list.append(mel)\n",
    "            \n",
    "        img_gt_list = np.stack(img_gt_list)\n",
    "        img_gt_masked_list = np.stack(img_gt_masked_list)\n",
    "        img_ip_list = np.stack(img_ip_list)\n",
    "        mel_list = np.stack(mel_list)\n",
    "        \n",
    "        yield(img_gt_list, img_gt_masked_list, img_ip_list, mel_list)\n",
    "        \n",
    "dataset = tf.data.Dataset.from_generator(gen, \n",
    "     (tf.float32, tf.float32, tf.float32, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "for step, data in enumerate(dataset):\n",
    "    print(data[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
